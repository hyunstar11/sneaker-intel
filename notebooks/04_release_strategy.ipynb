{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Release Strategy & Launch Optimization\n\n**Business Question:** When should Nike drop a shoe, at what price, through which channels, and how should inventory be allocated?\n\nThis notebook analyzes two complementary datasets to answer that question:\n- **StockX 2019** (99K transactions) â€” Yeezy & Off-White limited releases â†’ hype dynamics, size runs, geographic demand\n- **Market 2023** (2K products, 23 brands) â€” broad market snapshot â†’ timing, pricing, brand positioning\n\nEach section surfaces a data-driven insight and closes with an operational recommendation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:03:46.228643Z",
     "iopub.status.busy": "2026-02-17T02:03:46.228446Z",
     "iopub.status.idle": "2026-02-17T02:03:48.628810Z",
     "shell.execute_reply": "2026-02-17T02:03:48.627666Z"
    }
   },
   "outputs": [],
   "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\n\nfrom sneaker_intel.data import load_dataset, DatasetType\nfrom sneaker_intel.visualization.style import apply_nike_style\n\napply_nike_style()\n\n# â”€â”€ Market 2023 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmkt = load_dataset(DatasetType.MARKET_2023)\n# Drop rows with infinite or missing pricePremium (retail = $0 edge cases)\nmkt = mkt[np.isfinite(mkt['pricePremium'])].copy()\nmkt['release'] = pd.to_datetime(mkt['release'], errors='coerce')\nmkt['release_month'] = mkt['release'].dt.month\nmkt['release_month_name'] = mkt['release'].dt.strftime('%b')\nmkt['release_dow'] = mkt['release'].dt.day_name()\n\n# Focus on the four main brands for cleaner comparisons\nCORE_BRANDS = ['Nike', 'Jordan', 'adidas', 'New Balance']\nmkt_core = mkt[mkt['brand'].isin(CORE_BRANDS)].copy()\n\nprint(f\"Market 2023: {len(mkt):,} products | {mkt['brand'].nunique()} brands\")\nprint(f\"Core brands subset: {len(mkt_core):,} products\")\nprint(f\"Price premium range: {mkt['pricePremium'].min():.2f}x to {mkt['pricePremium'].max():.2f}x\")\n\n# â”€â”€ StockX 2019 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nstx = load_dataset(DatasetType.STOCKX)\n\ndef clean_price(s):\n    return pd.to_numeric(str(s).replace('$', '').replace(',', ''), errors='coerce')\n\nstx['sale_price']    = stx['Sale Price'].apply(clean_price)\nstx['retail_price']  = stx['Retail Price'].apply(clean_price)\nstx['order_date']    = pd.to_datetime(stx['Order Date'], format='%m/%d/%y', errors='coerce')\nstx['release_date']  = pd.to_datetime(stx['Release Date'], format='%m/%d/%y', errors='coerce')\nstx['days_post_release'] = (stx['order_date'] - stx['release_date']).dt.days\nstx['premium_pct']   = (stx['sale_price'] - stx['retail_price']) / stx['retail_price'] * 100\nstx = stx[stx['days_post_release'].between(0, 365)].copy()\n\nprint(f\"\\nStockX: {len(stx):,} transactions | brands: {stx['Brand'].unique()}\")\nprint(f\"Date range: {stx['order_date'].min().date()} â†’ {stx['order_date'].max().date()}\")\nprint(f\"Median premium: {stx['premium_pct'].median():.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:03:48.659798Z",
     "iopub.status.busy": "2026-02-17T02:03:48.659526Z",
     "iopub.status.idle": "2026-02-17T02:03:48.952761Z",
     "shell.execute_reply": "2026-02-17T02:03:48.952069Z"
    }
   },
   "outputs": [],
   "source": "## 1. Market Landscape â€” Brand Positioning\n\nBefore optimizing release strategy, understand where each brand sits in the market.\n**Key dimensions:** price premium (brand heat) vs. deadstock volume (market depth) vs. volatility (speculator interest).\n\nA brand in the **top-right quadrant** (high premium, high volume) has the ideal profile for a limited release:\ndemand exceeds supply and the secondary market is liquid enough for buyers to transact quickly."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T02:03:48.954473Z",
     "iopub.status.busy": "2026-02-17T02:03:48.954332Z",
     "iopub.status.idle": "2026-02-17T02:03:49.059974Z",
     "shell.execute_reply": "2026-02-17T02:03:49.059401Z"
    }
   },
   "outputs": [],
   "source": "brand_pos = (\n    mkt_core.groupby('brand')\n    .agg(\n        avg_premium=('pricePremium', 'median'),\n        total_volume=('deadstockSold', 'sum'),\n        avg_volatility=('volatility', 'mean'),\n        products=('item', 'count'),\n    )\n    .reset_index()\n)\n\nBRAND_COLORS = {\n    'Nike': '#111111', 'Jordan': '#CC0000',\n    'adidas': '#0055A4', 'New Balance': '#CF6F28'\n}\n\nfig, ax = plt.subplots(figsize=(10, 7))\n\nfor _, row in brand_pos.iterrows():\n    color = BRAND_COLORS.get(row['brand'], '#888888')\n    ax.scatter(\n        row['total_volume'] / 1_000,\n        row['avg_premium'],\n        s=row['avg_volatility'] * 8000,\n        color=color,\n        alpha=0.75,\n        edgecolors='white',\n        linewidth=1.5,\n        zorder=3,\n        label=row['brand'],\n    )\n    ax.annotate(\n        row['brand'],\n        (row['total_volume'] / 1_000, row['avg_premium']),\n        xytext=(12, 0), textcoords='offset points',\n        fontsize=12, fontweight='bold', color=color,\n    )\n\n# Quadrant lines\nax.axhline(brand_pos['avg_premium'].mean(), color='#cccccc', linestyle='--', lw=1, zorder=1)\nax.axvline(brand_pos['total_volume'].mean() / 1_000, color='#cccccc', linestyle='--', lw=1, zorder=1)\n\nax.set_xlabel('Deadstock Volume (thousands of units)', fontsize=12)\nax.set_ylabel('Median Price Premium (Ã— retail)', fontsize=12)\nax.set_title('Brand Positioning Matrix\\n(bubble size = avg. market volatility)', fontsize=14, fontweight='bold')\nax.text(0.98, 0.98, 'Bubble size = volatility', transform=ax.transAxes,\n        ha='right', va='top', fontsize=9, color='#888888')\nplt.tight_layout()\nplt.show()\n\nprint(brand_pos.set_index('brand').round(3).to_string())"
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Release Timing â€” When to Drop\n\nNot all months are equal. Consumer spending patterns, holiday calendars, and event cycles (back-to-school, All-Star Weekend, holiday gifting) all affect how aggressively the secondary market prices a new release.\n\n**Hypothesis:** Q4 drops (Octâ€“Dec) command higher premiums due to gift-buying demand and year-end consumer spending peaks.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "MONTH_ORDER = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\nDOW_ORDER   = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n\ntiming_monthly = (\n    mkt_core.dropna(subset=['release_month'])\n    .groupby('release_month_name')['pricePremium']\n    .agg(['median', 'count', 'std'])\n    .reindex(MONTH_ORDER)\n    .dropna()\n    .reset_index()\n    .rename(columns={'release_month_name': 'month', 'median': 'median_premium',\n                     'count': 'n_products', 'std': 'std_premium'})\n)\n\ntiming_dow = (\n    mkt_core.dropna(subset=['release_dow'])\n    .groupby('release_dow')['pricePremium']\n    .agg(['median', 'count'])\n    .reindex(DOW_ORDER)\n    .dropna()\n    .reset_index()\n    .rename(columns={'release_dow': 'dow', 'median': 'median_premium', 'count': 'n_products'})\n)\n\n# Dynamically identify top 3 months\ntop3_months = set(timing_monthly.nlargest(3, 'median_premium')['month'])\ntop2_days   = set(timing_dow.nlargest(2, 'median_premium')['dow'])\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\noverall_median = mkt_core['pricePremium'].median()\n\n# Monthly\ncolors_month = ['#CC0000' if m in top3_months else '#AAAAAA' for m in timing_monthly['month']]\nbars = axes[0].bar(timing_monthly['month'], timing_monthly['median_premium'], color=colors_month, width=0.7)\naxes[0].axhline(overall_median, color='#333333', linestyle='--', linewidth=1.2,\n                label=f'Overall median: {overall_median:.2f}x')\naxes[0].set_title('Median Resale Premium by Release Month\\n(Nike, Jordan, adidas, New Balance)',\n                  fontsize=13, fontweight='bold')\naxes[0].set_xlabel('Release Month')\naxes[0].set_ylabel('Median Price Premium (Ã— retail)')\naxes[0].legend(fontsize=9)\naxes[0].set_ylim(0, timing_monthly['median_premium'].max() * 1.3)\nfor bar, val in zip(bars, timing_monthly['median_premium']):\n    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n                 f'{val:.2f}x', ha='center', va='bottom', fontsize=8.5, fontweight='bold')\n\n# Day of week\ncolors_dow = ['#CC0000' if d in top2_days else '#AAAAAA' for d in timing_dow['dow']]\nbars2 = axes[1].bar(timing_dow['dow'], timing_dow['median_premium'], color=colors_dow, width=0.7)\naxes[1].axhline(overall_median, color='#333333', linestyle='--', linewidth=1.2)\naxes[1].set_title('Median Resale Premium by Release Day', fontsize=13, fontweight='bold')\naxes[1].set_xlabel('Day of Week')\naxes[1].set_ylabel('Median Price Premium (Ã— retail)')\naxes[1].set_xticklabels(timing_dow['dow'], rotation=30, ha='right')\naxes[1].set_ylim(0, timing_dow['median_premium'].max() * 1.3)\nfor bar, val in zip(bars2, timing_dow['median_premium']):\n    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n                 f'{val:.2f}x', ha='center', va='bottom', fontsize=8.5, fontweight='bold')\n\nplt.suptitle('Timing Is Strategy', fontsize=15, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\nbest_months = timing_monthly.nlargest(3, 'median_premium')\nbest_day    = timing_dow.loc[timing_dow['median_premium'].idxmax(), 'dow']\nprint(\"Top 3 release months by median premium:\")\nprint(best_months[['month','median_premium','n_products']].to_string(index=False))\nprint(f\"\\nBest release day: {best_day}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Pricing Strategy â€” Finding the Sweet Spot\n\nRetail price is not just a cost signal â€” it's a positioning signal. Setting price too low creates immediate sell-out but leaves margin on the table and invites scalpers. Setting it too high reduces aspiration and slows sell-through.\n\nThe resale premium is a direct measure of **unmet demand at retail price**. We want to find the retail price range where that premium is highest â€” that's the zone where consumers perceive maximum value relative to what Nike is charging.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "bins   = [0, 100, 125, 150, 175, 200, 250, 300, float('inf')]\nlabels = ['<$100','$100â€“125','$125â€“150','$150â€“175','$175â€“200','$200â€“250','$250â€“300','$300+']\n\n# Use core brands only: Crocs/Converse at <$100 would otherwise distort the analysis\nmkt_core['price_bin'] = pd.cut(mkt_core['retail'], bins=bins, labels=labels)\n\npricing = (\n    mkt_core.groupby('price_bin', observed=True)\n    .agg(\n        median_premium=('pricePremium', 'median'),\n        median_bids=('numberOfBids', 'median'),\n        products=('item', 'count'),\n        median_sales=('salesThisPeriod', 'median'),\n    )\n    .reset_index()\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\nsweet_spot_idx = pricing['median_premium'].idxmax()\nbar_colors = ['#CC0000' if i == sweet_spot_idx else '#AAAAAA' for i in range(len(pricing))]\nbars = axes[0].bar(pricing['price_bin'], pricing['median_premium'], color=bar_colors, width=0.7)\naxes[0].axhline(mkt_core['pricePremium'].median(), color='#333333', linestyle='--', linewidth=1.2,\n                label='Overall median (core brands)')\naxes[0].set_title('Median Resale Premium by Retail Price\\n(Nike, Jordan, adidas, New Balance)',\n                  fontsize=13, fontweight='bold')\naxes[0].set_xlabel('Retail Price Range')\naxes[0].set_ylabel('Median Price Premium (Ã— retail)')\naxes[0].set_xticklabels(pricing['price_bin'], rotation=35, ha='right')\naxes[0].legend(fontsize=9)\nfor bar, val in zip(bars, pricing['median_premium']):\n    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n                 f'{val:.2f}x', ha='center', va='bottom', fontsize=8.5, fontweight='bold')\n\n# Bid depth\naxes[1].bar(pricing['price_bin'], pricing['median_bids'], color='#AAAAAA', width=0.7)\naxes[1].bar(pricing.loc[sweet_spot_idx, 'price_bin'], pricing.loc[sweet_spot_idx, 'median_bids'],\n            color='#CC0000', width=0.7)\naxes[1].set_title('Median Active Bids by Retail Price\\n(demand depth proxy)', fontsize=13, fontweight='bold')\naxes[1].set_xlabel('Retail Price Range')\naxes[1].set_ylabel('Median Number of Active Bids')\naxes[1].set_xticklabels(pricing['price_bin'], rotation=35, ha='right')\n\nplt.suptitle('Pricing Strategy: The Sweet Spot', fontsize=15, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\nsweet_range   = pricing.loc[sweet_spot_idx, 'price_bin']\nsweet_premium = pricing.loc[sweet_spot_idx, 'median_premium']\nprint(f\"Peak premium band: {sweet_range} â†’ {sweet_premium:.2f}x median premium\")\nprint(f\"\\nCore brand pricing table:\")\nprint(pricing.set_index('price_bin').round(3).to_string())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Hype Resilience â€” How Long Does Demand Stay Elevated?\n\nFor most consumer products, demand decays quickly after launch. For *truly* limited releases, the story is different â€” Yeezy and Off-White in 2018 were culturally significant enough to behave as store-of-value assets.\n\nThis analysis asks: **does the secondary market premium compress over time, or does it hold?** The answer determines whether Nike needs to defend against grey-market flooding or can rely on sustained secondary market health to reinforce brand aspiration.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "stx['week_post_release'] = (stx['days_post_release'] // 7) * 7\n\ndecay_all = (\n    stx[stx['days_post_release'] <= 180]\n    .groupby('week_post_release')['premium_pct']\n    .agg(['median', 'q25', 'q75'])\n    .reset_index()\n)\ndecay_all.columns = ['days', 'median', 'q25', 'q75']\n\ndecay_by_brand = (\n    stx[stx['days_post_release'] <= 180]\n    .groupby([stx['Brand'].str.strip(), 'week_post_release'])['premium_pct']\n    .median()\n    .reset_index()\n    .rename(columns={'week_post_release': 'days', 'premium_pct': 'median_premium_pct'})\n)\n\npeak_premium = stx[stx['days_post_release'] <= 14]['premium_pct'].median()\nlate_premium = stx[stx['days_post_release'].between(60, 90)]['premium_pct'].median()\nchange_pct   = (late_premium - peak_premium) / abs(peak_premium) * 100 if peak_premium != 0 else 0\ndirection    = 'increased' if change_pct > 0 else 'decreased'\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\nax = axes[0]\nax.fill_between(decay_all['days'], decay_all['q25'], decay_all['q75'],\n                alpha=0.15, color='#CC0000', label='IQR (25â€“75th pct)')\nax.plot(decay_all['days'], decay_all['median'], color='#CC0000', linewidth=2.5, label='Median premium')\nax.axvline(14, color='#333333', linestyle='--', linewidth=1.2, label='Day 14')\nax.axvline(60, color='#888888', linestyle=':', linewidth=1.2, label='Day 60')\nax.annotate(f'Day 0â€“14: {peak_premium:.0f}%',\n            xy=(7, peak_premium), xytext=(25, peak_premium - 15),\n            arrowprops=dict(arrowstyle='->', color='#333333'), fontsize=9)\nax.annotate(f'Day 60â€“90: {late_premium:.0f}%\\n({change_pct:+.0f}%)',\n            xy=(75, late_premium), xytext=(95, late_premium - 20),\n            arrowprops=dict(arrowstyle='->', color='#333333'), fontsize=9)\nax.set_title('Resale Premium Over Time â€” All Limited Releases\\n(Yeezy + Off-White, 2018)',\n             fontsize=13, fontweight='bold')\nax.set_xlabel('Days After Release')\nax.set_ylabel('Median Resale Premium (%)')\nax.legend(fontsize=9)\nax.yaxis.set_major_formatter(mticker.PercentFormatter())\n\nBRAND_COLORS = {'Yeezy': '#111111', 'Off-White': '#CC0000'}\nfor brand, grp in decay_by_brand.groupby('Brand'):\n    axes[1].plot(grp['days'], grp['median_premium_pct'], linewidth=2.5,\n                 label=brand, color=BRAND_COLORS.get(brand, '#888888'))\naxes[1].axvline(14, color='#AAAAAA', linestyle='--', linewidth=1)\naxes[1].set_title('Premium Trajectory by Brand', fontsize=13, fontweight='bold')\naxes[1].set_xlabel('Days After Release')\naxes[1].set_ylabel('Median Resale Premium (%)')\naxes[1].legend(fontsize=10)\naxes[1].yaxis.set_major_formatter(mticker.PercentFormatter())\n\ntitle = 'Investment-Grade Drops: Premium Held, Not Decayed' if change_pct > -5 else 'Hype Has a Half-Life'\nplt.suptitle(title, fontsize=15, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\nprint(f\"Median premium â€” first 14 days:  {peak_premium:.1f}%\")\nprint(f\"Median premium â€” days 60â€“90:     {late_premium:.1f}%\")\nprint(f\"Change:                          {change_pct:+.1f}% ({direction})\")\nprint()\nif abs(change_pct) < 10:\n    print(\"Finding: Premium remained remarkably stable â€” these releases behaved as\")\n    print(\"store-of-value assets, not typical consumer goods subject to rapid depreciation.\")\n    print(\"Implication: Nike can support a no-restock policy without losing secondary\")\n    print(\"market health, as strong demand persists well beyond the initial drop window.\")\nelse:\n    print(f\"Finding: Premium {direction} by {abs(change_pct):.0f}% from peak to day 60â€“90.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Geographic Demand â€” Where to Allocate\n\nThe resale market is not uniformly distributed. Supply allocation decisions have real consequences: under-supplying high-demand markets drives secondary market inflation and consumer frustration. Over-supplying them dilutes exclusivity.\n\nStockX buyer region data shows where the strongest demand pockets sit â€” a proxy for Nike's allocation priorities across SNKRS geofencing, retailer door selection, and DTC inventory decisions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "geo = (\n    stx.groupby('Buyer Region')\n    .agg(\n        transactions=('sale_price', 'count'),\n        median_premium=('premium_pct', 'median'),\n        total_spend=('sale_price', 'sum'),\n    )\n    .sort_values('transactions', ascending=False)\n    .reset_index()\n)\ngeo['share_pct'] = geo['transactions'] / geo['transactions'].sum() * 100\ngeo['cumulative_share'] = geo['share_pct'].cumsum()\n\nTOP_N = 15\ngeo_top = geo.head(TOP_N)\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# Left: transaction share\nbar_colors = ['#CC0000' if i < 2 else '#AAAAAA' for i in range(TOP_N)]\nbars = axes[0].barh(geo_top['Buyer Region'][::-1], geo_top['transactions'][::-1],\n                    color=bar_colors[::-1])\naxes[0].set_title(f'Top {TOP_N} States by Resale Transaction Volume', fontsize=13, fontweight='bold')\naxes[0].set_xlabel('Number of Transactions')\n\nfor bar, val, share in zip(bars, geo_top['transactions'][::-1], geo_top['share_pct'][::-1]):\n    axes[0].text(bar.get_width() + 100, bar.get_y() + bar.get_height()/2,\n                 f'{share:.1f}%', va='center', fontsize=9)\n\n# Right: cumulative concentration curve\naxes[1].plot(range(1, len(geo) + 1), geo['cumulative_share'],\n             color='#CC0000', linewidth=2.5)\naxes[1].axhline(50, color='#AAAAAA', linestyle='--', linewidth=1, label='50% of demand')\naxes[1].axhline(75, color='#888888', linestyle=':', linewidth=1, label='75% of demand')\n\n# Annotate how many states cover 50% and 75%\nstates_50 = (geo['cumulative_share'] <= 50).sum() + 1\nstates_75 = (geo['cumulative_share'] <= 75).sum() + 1\naxes[1].axvline(states_50, color='#AAAAAA', linestyle='--', linewidth=1)\naxes[1].axvline(states_75, color='#888888', linestyle=':', linewidth=1)\naxes[1].annotate(f'{states_50} states\\n= 50%', xy=(states_50, 50),\n                 xytext=(states_50 + 2, 40), fontsize=9)\naxes[1].annotate(f'{states_75} states\\n= 75%', xy=(states_75, 75),\n                 xytext=(states_75 + 2, 65), fontsize=9)\n\naxes[1].set_title('Demand Concentration Curve', fontsize=13, fontweight='bold')\naxes[1].set_xlabel('Number of States (ranked by volume)')\naxes[1].set_ylabel('Cumulative % of All Transactions')\naxes[1].legend(fontsize=9)\naxes[1].set_ylim(0, 105)\n\nplt.suptitle('Geographic Demand: Concentrated, Not Uniform', fontsize=15, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\ntop2_share = geo_top.head(2)['share_pct'].sum()\nprint(f\"Top 2 states ({geo_top.iloc[0]['Buyer Region']} + {geo_top.iloc[1]['Buyer Region']}): \"\n      f\"{top2_share:.1f}% of all transactions\")\nprint(f\"States needed to cover 50% of demand: {states_50}\")\nprint(f\"States needed to cover 75% of demand: {states_75}\")\nprint(f\"\\nTop 5 states:\")\nprint(geo_top[['Buyer Region','transactions','share_pct','median_premium']].head(5).to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Size Run Optimization\n\nProducing the wrong size distribution is expensive: excess inventory in unpopular sizes ties up capital and requires markdown, while stockouts in core sizes drive consumers to the secondary market (and competitors).\n\nThe StockX transaction data gives us the actual size distribution of *completed trades* â€” a pure demand signal uncorrupted by which sizes Nike chose to produce.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "size_dist = (\n    stx.groupby('Shoe Size')\n    .agg(transactions=('sale_price', 'count'), median_premium=('premium_pct', 'median'))\n    .reset_index()\n    .sort_values('Shoe Size')\n)\nsize_dist['demand_share'] = size_dist['transactions'] / size_dist['transactions'].sum() * 100\nsize_dist['cumulative']   = size_dist['demand_share'].cumsum()\n\n# Core sizes: those covering the middle 75% of demand\ncore_mask = (size_dist['cumulative'] >= 12.5) & (size_dist['cumulative'] <= 87.5)\ncore_sizes = size_dist[core_mask]['Shoe Size'].tolist()\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\nbar_colors = ['#CC0000' if sz in core_sizes else '#DDDDDD' for sz in size_dist['Shoe Size']]\nbars = axes[0].bar(size_dist['Shoe Size'].astype(str), size_dist['demand_share'],\n                   color=bar_colors, width=0.8)\naxes[0].set_title('Resale Transaction Share by Shoe Size\\n(red = core 75% demand window)', fontsize=13, fontweight='bold')\naxes[0].set_xlabel('Shoe Size (US Men\\'s)')\naxes[0].set_ylabel('% of All Transactions')\naxes[0].tick_params(axis='x', rotation=45)\n\n# Cumulative demand curve\naxes[1].plot(size_dist['Shoe Size'], size_dist['cumulative'], color='#CC0000', linewidth=2.5)\nfor threshold, label in [(25, '25%'), (50, '50%'), (75, '75%')]:\n    axes[1].axhline(threshold, color='#AAAAAA', linestyle='--', linewidth=1)\n    size_at = size_dist[size_dist['cumulative'] >= threshold]['Shoe Size'].iloc[0]\n    axes[1].annotate(f'Size {size_at} = {label}',\n                     xy=(size_at, threshold), xytext=(size_at + 0.5, threshold - 6),\n                     fontsize=9, color='#555555')\naxes[1].set_title('Cumulative Demand by Size', fontsize=13, fontweight='bold')\naxes[1].set_xlabel('Shoe Size (US Men\\'s)')\naxes[1].set_ylabel('Cumulative % of Demand')\naxes[1].set_ylim(0, 105)\n\nplt.suptitle('Size Run Optimization: Concentrate Production in Core Sizes', fontsize=15, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\ncore_share = size_dist[core_mask]['demand_share'].sum()\nprint(f\"Core sizes covering middle 75% of demand: {[float(s) for s in core_sizes]}\")\nprint(f\"Those {len(core_sizes)} sizes account for {core_share:.1f}% of transactions\")\nprint(f\"\\nSize distribution stats:\")\nprint(f\"  Median size: {size_dist.loc[size_dist['cumulative'] >= 50, 'Shoe Size'].iloc[0]}\")\nprint(f\"  Sizes below 8: {size_dist[size_dist['Shoe Size'] < 8]['demand_share'].sum():.1f}% of demand\")\nprint(f\"  Sizes above 13: {size_dist[size_dist['Shoe Size'] > 13]['demand_share'].sum():.1f}% of demand\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Strategic Recommendations\n\nDrawing together all five analyses into an actionable release playbook.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Build the recommendation table dynamically from actual data\nbest_month      = timing_monthly.loc[timing_monthly['median_premium'].idxmax(), 'month']\nbest_day        = timing_dow.loc[timing_dow['median_premium'].idxmax(), 'dow']\npeak_month_prem = timing_monthly['median_premium'].max()\noverall_prem    = timing_monthly['median_premium'].mean()\ntiming_uplift   = (peak_month_prem - overall_prem) / overall_prem * 100\n\nsweet_label     = pricing.loc[sweet_spot_idx, 'price_bin']\nsweet_premium_v = pricing.loc[sweet_spot_idx, 'median_premium']\n\ntop_state_1     = geo_top.iloc[0]['Buyer Region']\ntop_state_2     = geo_top.iloc[1]['Buyer Region']\ntop2_pct        = geo_top.head(2)['share_pct'].sum()\n\ndecay_note = f\"{(peak_premium - late_premium)/peak_premium*100:.0f}%\" if peak_premium > 0 else \"N/A\"\n\nrecommendations = [\n    {\n        'Area': 'ğŸ“… Release Timing',\n        'Recommendation': f\"Target {best_month} drops, {best_day} release day\",\n        'Evidence': f\"{best_month} shows {peak_month_prem:.2f}x median premium \"\n                    f\"({timing_uplift:+.0f}% vs annual average); \"\n                    f\"{best_day} releases capture weekend consumer attention\",\n        'Expected Impact': f\"+{timing_uplift:.0f}% resale premium vs. off-peak months\",\n    },\n    {\n        'Area': 'ğŸ’° Retail Pricing',\n        'Recommendation': f\"Price limited releases in the {sweet_label} range\",\n        'Evidence': f\"This band generates {sweet_premium_v:.2f}x median resale premium. \"\n                    \"Below $125 signals low exclusivity; above $250 suppresses demand breadth\",\n        'Expected Impact': \"Maximizes unmet demand signal without restricting total addressable market\",\n    },\n    {\n        'Area': 'â±ï¸ Restock / Restocking Policy',\n        'Recommendation': \"No restock within first 60 days for limited releases\",\n        'Evidence': f\"Premium decays ~{decay_note} from peak (days 0â€“14) to days 60â€“90. \"\n                    \"Early restock announcement collapses secondary market and signals oversupply\",\n        'Expected Impact': \"Preserves brand heat during the peak demand window; \"\n                           \"secondary market price stability supports brand aspiration\",\n    },\n    {\n        'Area': 'ğŸ—ºï¸ Geographic Allocation',\n        'Recommendation': f\"Weight SNKRS geofencing and retailer doors toward {top_state_1} and {top_state_2}\",\n        'Evidence': f\"{top_state_1} + {top_state_2} = {top2_pct:.1f}% of all resale transactions. \"\n                    f\"Demand covers 50% of volume in only {states_50} states\",\n        'Expected Impact': \"Reduces secondary market friction in highest-demand markets; \"\n                           \"improves consumer satisfaction and SNKRS win-rate equity\",\n    },\n    {\n        'Area': 'ğŸ‘Ÿ Size Run',\n        'Recommendation': f\"Concentrate production in sizes {float(core_sizes[0])}â€“{float(core_sizes[-1])} (full run); \"\n                           \"half-size or quarter-size runs outside this window\",\n        'Evidence': f\"Core sizes {[float(s) for s in core_sizes]} capture \"\n                    f\"{core_share:.0f}% of demand. Extended sizes add production cost with <{100-core_share:.0f}% demand share\",\n        'Expected Impact': \"Reduces excess inventory on tail sizes; \"\n                           \"improves sell-through rate and reduces markdown exposure\",\n    },\n]\n\nrec_df = pd.DataFrame(recommendations)\n\n# Display as formatted table\npd.set_option('display.max_colwidth', 120)\nprint(\"=\" * 90)\nprint(\"RELEASE STRATEGY PLAYBOOK â€” DATA-DRIVEN RECOMMENDATIONS\")\nprint(\"=\" * 90)\nfor _, row in rec_df.iterrows():\n    print(f\"\\n{row['Area']}\")\n    print(f\"  â†’ {row['Recommendation']}\")\n    print(f\"  Evidence: {row['Evidence']}\")\n    print(f\"  Impact:   {row['Expected Impact']}\")\nprint(\"\\n\" + \"=\" * 90)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}